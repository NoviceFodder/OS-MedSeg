{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "induced-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import warnings\n",
    "import glob\n",
    "import torch\n",
    "import time\n",
    "import utils\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import pystrum.pynd.ndutils as nd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from my_unet import myUNet,teacher_student_model,UNet_distill\n",
    "from utils import pkload\n",
    "#from dataset import Seg_CT_MRI_Dataset\n",
    "# MONAI imports\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from monai.config import print_config\n",
    "from monai.transforms.post.array import AsDiscrete\n",
    "from monai.metrics import DiceMetric,HausdorffDistanceMetric,SurfaceDistanceMetric,PSNRMetric,MSEMetric\n",
    "from monai.metrics.regression import SSIMMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c5e929-1c7a-41f6-8405-f735abc47e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seg_CT_MRI_Dataset(Dataset):\n",
    "    def __init__(self, source_root_dir,transform2img=None,transform2both=None,is_Training=True,is_val=False):\n",
    "        \n",
    "        self.source_root_dir = source_root_dir\n",
    "        #self.target_root_dir = target_root_dir\n",
    "        self.transform2img = transform2img\n",
    "        self.transform2both = transform2both\n",
    "        #self.is_Training = is_Training\n",
    "        # 获取所有子文件夹的名称\n",
    "        if is_Training:\n",
    "            self.source_subfolders = [subfolder for subfolder in os.listdir(source_root_dir)][:70]\n",
    "        elif is_val:\n",
    "            self.source_subfolders = [subfolder for subfolder in os.listdir(source_root_dir)][70:88]\n",
    "        else:\n",
    "            #self.source_subfolders = [subfolder for subfolder in os.listdir(source_root_dir)][88:]\n",
    "            #self.source_subfolders = [subfolder for subfolder in os.listdir(source_root_dir)][70:]\n",
    "            self.source_subfolders=[]\n",
    "            test_set=[71,72,74,75,77,79,80,85,87]\n",
    "            delete_list = [91,92,95,96,98,101,102,103,105,106,107,109,111,113,115,116]\n",
    "\n",
    "            for i in range(89,119):\n",
    "                if i not in delete_list:\n",
    "                    test_set.append(i)\n",
    "            self.source_subfolders=[]\n",
    "            for i in range(len(test_set)):\n",
    "                idx = test_set[i]\n",
    "                self.source_subfolders.append(f\"BCH_CT{idx:03}\")    \n",
    "                #self.target_subfolders = [subfolder for subfolder in os.listdir(target_root_dir)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.source_subfolders) \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        source_subfolder = self.source_subfolders[idx]\n",
    "        #print(source_subfolder)\n",
    "        #print(self.source_subfolders)\n",
    "        \n",
    "        # 构建源图像和目标图像的文件路径\n",
    "        source_path = os.path.join(self.source_root_dir, source_subfolder, \"brain_small_norm.nii.gz\")\n",
    "        source_label_path = os.path.join(self.source_root_dir, source_subfolder, \"label_small.nii.gz\")\n",
    "        #print('real ct image path: ',source_path)\n",
    "        #source_path = os.path.join(self.source_root_dir, source_subfolder, \"pred_image_rigid.nii.gz\")\n",
    "        #source_label_path = os.path.join(self.source_root_dir, source_subfolder, \"pred_label_rigid.nii.gz\")\n",
    "        # 检查文件是否存在\n",
    "        if not os.path.exists(source_path) :\n",
    "            raise FileNotFoundError(f\"Source file not found for subfolder {source_path}\")\n",
    "\n",
    "        source_image_sitk = sitk.ReadImage(source_path)\n",
    "        source_label_sitk = sitk.ReadImage(source_label_path)\n",
    "\n",
    "        source_image_np = sitk.GetArrayFromImage(source_image_sitk) #Converting sitk_metadata to image Array\n",
    "        source_label_np = sitk.GetArrayFromImage(source_label_sitk)\n",
    "       \n",
    "        label_mapping = {\n",
    "            0.0: 0,\n",
    "            1.0: 1,\n",
    "            2.0: 2,\n",
    "            3.0: 1,\n",
    "            4.0: 2,\n",
    "            5.0: 1,\n",
    "            6.0: 2,\n",
    "            7.0: 1,\n",
    "            8.0: 2,\n",
    "            9.0: 4,\n",
    "            10.0: 3,\n",
    "            11.0: 4,\n",
    "            12.0: 3,\n",
    "            13.0: 0,\n",
    "            14.0: 1,\n",
    "            15.0: 2,\n",
    "            16.0: 0,\n",
    "            17.0: 0,\n",
    "            18.0: 1,\n",
    "            19.0: 2,\n",
    "            20.0: 6,\n",
    "            21.0: 5,\n",
    "            24.0: 6,\n",
    "            25.0: 5,\n",
    "            28.0: 0,\n",
    "            29.0: 1,\n",
    "            30.0: 2\n",
    "        }\n",
    "        '''\n",
    "        # 创建分类标签值到连续整数的映射\n",
    "        label_mapping = {\n",
    "            0.0: 0,\n",
    "            1.0: 1,\n",
    "            2.0: 2,\n",
    "            3.0: 3,\n",
    "            4.0: 4,\n",
    "            5.0: 5,\n",
    "            6.0: 6,\n",
    "            7.0: 7,\n",
    "            8.0: 8,\n",
    "            9.0: 9,\n",
    "            10.0: 10,\n",
    "            11.0: 11,\n",
    "            12.0: 12,\n",
    "            13.0: 13,\n",
    "            14.0: 14,\n",
    "            15.0: 15,\n",
    "            16.0: 16,\n",
    "            17.0: 17,\n",
    "            18.0: 18,\n",
    "            19.0: 19,\n",
    "            20.0: 20,\n",
    "            21.0: 21,\n",
    "            24.0: 22,\n",
    "            25.0: 23,\n",
    "            28.0: 24,\n",
    "            29.0: 25,\n",
    "            30.0: 26\n",
    "        }\n",
    "        '''\n",
    "        # 使用映射替换标签数组中的值\n",
    "        for old_label, new_label in label_mapping.items():\n",
    "            source_label_np[source_label_np == old_label] = new_label\n",
    "        \n",
    "        # 现在，label1_array 包含了连续的整数值\n",
    "        source_label_np = source_label_np.astype(int)\n",
    "\n",
    "\n",
    "        source_image = torch.Tensor(source_image_np).unsqueeze(dim = 0)\n",
    "\n",
    "        source_label = torch.Tensor(source_label_np).unsqueeze(dim = 0)\n",
    "\n",
    "        data_dict = {'image': source_image, \"label\": source_label}\n",
    "\n",
    "        # Apply transformation\n",
    "        if self.transform2img:\n",
    "            source_image = apply_transform(self.transform2img, source_image)\n",
    "\n",
    "        if self.transform2both:\n",
    "            trans_data = apply_transform(self.transform2both, data_dict)\n",
    "            source_image = trans_data['image']\n",
    "            source_label = trans_data['label']\n",
    "            \n",
    "            \n",
    "        return source_image,source_label,source_subfolder,source_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af328e62-b599-4647-b502-917e1e53c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seg_OASIS_Dataset(Dataset):\n",
    "    def __init__(self, source_root_dir,transform2img=None,transform2both=None,is_Training=True,is_val=False):\n",
    "        \n",
    "        self.source_root_dir = source_root_dir\n",
    "        #self.target_root_dir = target_root_dir\n",
    "        self.transform2img = transform2img\n",
    "        self.transform2both = transform2both\n",
    "        #self.is_Training = is_Training\n",
    "        # 获取所有子文件夹的名称\n",
    "        \n",
    "        if is_Training:\n",
    "            self.source_subfolders = [subfolder for subfolder in os.listdir(source_root_dir)][:335]\n",
    "\n",
    "        elif is_val:\n",
    "            self.source_subfolders = [subfolder for subfolder in os.listdir(source_root_dir)][335:375]\n",
    "        else:\n",
    "            self.source_subfolders = [subfolder for subfolder in os.listdir(source_root_dir)][375:]\n",
    "        #self.target_subfolders = [subfolder for subfolder in os.listdir(target_root_dir)]\n",
    "        \n",
    "        #self.source_subfolders = [subfolder for subfolder in os.listdir(source_root_dir)]\n",
    "    def __len__(self):\n",
    "        return len(self.source_subfolders) \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        source_subfolder = self.source_subfolders[idx]\n",
    "        #print(source_subfolder)\n",
    "        #print(self.source_subfolders)\n",
    "        \n",
    "        # 构建源图像和目标图像的文件路径\n",
    "        source_path = os.path.join(self.source_root_dir, source_subfolder, \"aligned_norm.nii.gz\")\n",
    "        source_label_path = os.path.join(self.source_root_dir, source_subfolder, \"aligned_seg35.nii.gz\")\n",
    "        #print('source_path: ',source_path)\n",
    "\n",
    "        # 检查文件是否存在\n",
    "        if not os.path.exists(source_path) :\n",
    "            raise FileNotFoundError(f\"Source file not found for subfolder {source_subfolder}\")\n",
    "\n",
    "        source_image_sitk = sitk.ReadImage(source_path)\n",
    "        source_label_sitk = sitk.ReadImage(source_label_path)\n",
    "\n",
    "        source_image_np = sitk.GetArrayFromImage(source_image_sitk) #Converting sitk_metadata to image Array\n",
    "        source_label_np = sitk.GetArrayFromImage(source_label_sitk)\n",
    "\n",
    "        # 现在，label1_array 包含了连续的整数值\n",
    "        #source_label_np = source_label_np.astype(int)\n",
    "        source_image = torch.Tensor(source_image_np).unsqueeze(dim = 0)\n",
    "\n",
    "        source_label = torch.Tensor(source_label_np).unsqueeze(dim = 0)\n",
    "\n",
    "        data_dict = {'image': source_image, \"label\": source_label}\n",
    "\n",
    "        # Apply transformation\n",
    "        if self.transform2img:\n",
    "            source_image = apply_transform(self.transform2img, source_image)\n",
    "\n",
    "        if self.transform2both:\n",
    "            trans_data = apply_transform(self.transform2both, data_dict)\n",
    "            source_image = trans_data['image']\n",
    "            source_label = trans_data['label']\n",
    "            \n",
    "            \n",
    "        return source_image,source_label,source_subfolder,source_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "858709ef-61b7-4662-a625-f977a72cc8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seg_IXI_Dataset(Dataset):\n",
    "    def __init__(self, source_root_dir,transform2img=None,transform2both=None,is_Training=True,is_val=False):\n",
    "        \n",
    "        self.source_root_dir = source_root_dir\n",
    "        self.transform2img = transform2img\n",
    "        self.transform2both = transform2both\n",
    "        #self.is_Training = is_Training\n",
    "        # 获取所有子文件夹的名称\n",
    "        \n",
    "        if is_Training:\n",
    "            self.source_files = [filename for filename in os.listdir(source_root_dir)]\n",
    "        elif is_val:\n",
    "            self.source_files = [filename for filename in os.listdir(source_root_dir)]\n",
    "        else:\n",
    "            self.source_files = [filename for filename in os.listdir(source_root_dir)]\n",
    "        #self.target_subfolders = [subfolder for subfolder in os.listdir(target_root_dir)]\n",
    "        \n",
    "        #self.source_subfolders = [subfolder for subfolder in os.listdir(source_root_dir)]\n",
    "    def __len__(self):\n",
    "        return len(self.source_files) \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        source_filename = self.source_files[idx]\n",
    "        #print(source_subfolder)\n",
    "        #print(self.source_subfolders)\n",
    "        \n",
    "        # 构建源图像和目标图像的文件路径\n",
    "        target_path = os.path.join(self.source_root_dir,source_filename)\n",
    "        target_image_np,target_label_np = pkload(target_path)\n",
    "    \n",
    "        target_image_np = np.transpose(target_image_np, (2,1,0))\n",
    "        target_label_np = np.transpose(target_label_np, (2,1,0))\n",
    "        \n",
    "        target_image_np = np.ascontiguousarray(target_image_np)\n",
    "        target_label_np = np.ascontiguousarray(target_label_np)\n",
    "        #[0, 2, 3, 4, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 24, 28, 31, 41, 42, 43, 46, 47, 49, 50, 51, 52, 53, 54, 60, 63]\n",
    "        label_mapping = {\n",
    "            0 : 0,\n",
    "            5 : 0,\n",
    "            26: 0,\n",
    "            30: 0,\n",
    "            44: 0,\n",
    "            58: 0,\n",
    "            62: 0,\n",
    "            72: 0,\n",
    "            77: 0,\n",
    "            80: 0,\n",
    "            85: 0,\n",
    "            251:0,\n",
    "            252:0,\n",
    "            253:0,\n",
    "            254:0,\n",
    "            255:0,\n",
    "            2: 1,\n",
    "            3: 2,\n",
    "            4: 3,\n",
    "            7: 4,\n",
    "            8: 5,\n",
    "            10: 6,\n",
    "            11: 7,\n",
    "            12: 8,\n",
    "            13: 9,\n",
    "            14: 10,\n",
    "            15: 11,\n",
    "            16: 12,\n",
    "            17: 13,\n",
    "            18: 14,\n",
    "            24: 15,\n",
    "            28: 16,\n",
    "            31: 17,\n",
    "            41: 18,\n",
    "            42: 19,\n",
    "            43: 20,\n",
    "            46: 21,\n",
    "            47: 22,\n",
    "            49: 23,\n",
    "            50: 24,\n",
    "            51: 25,\n",
    "            52: 26,\n",
    "            53: 27,\n",
    "            54: 28,\n",
    "            60: 29,\n",
    "            63: 30\n",
    "        }\n",
    "\n",
    "        # 使用映射替换标签数组中的值\n",
    "        for old_label, new_label in label_mapping.items():\n",
    "            target_label_np[target_label_np == old_label] = new_label\n",
    "        # 现在，label1_array 包含了连续的整数值\n",
    "        target_label_np = target_label_np.astype(int)  \n",
    "\n",
    "        # 现在，label1_array 包含了连续的整数值\n",
    "        target_image = torch.Tensor(target_image_np).unsqueeze(dim = 0)\n",
    "        target_label = torch.Tensor(target_label_np).unsqueeze(dim = 0)\n",
    "        \n",
    "        target_data_dict = {'image': target_image, \"label\": target_label}\n",
    "            \n",
    "        return target_image,target_label,source_filename,target_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-insert",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "burning-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.vals = []\n",
    "        self.std = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        self.vals.append(val)\n",
    "        self.std = np.std(self.vals)\n",
    "\n",
    "def dice_val(y_pred, y_true, num_clus):\n",
    "    y_pred = nn.functional.one_hot(y_pred, num_classes=num_clus)\n",
    "    y_pred = torch.squeeze(y_pred, 1)\n",
    "    y_pred = y_pred.permute(0, 4, 1, 2, 3).contiguous()\n",
    "    y_true = nn.functional.one_hot(y_true, num_classes=num_clus)\n",
    "    y_true = torch.squeeze(y_true, 1)\n",
    "    y_true = y_true.permute(0, 4, 1, 2, 3).contiguous()\n",
    "    # Exclude the background class\n",
    "    y_pred = y_pred[:, 1:]  # Assuming that background class is at index 0\n",
    "    y_true = y_true[:, 1:]\n",
    "    intersection = y_pred * y_true\n",
    "    intersection = intersection.sum(dim=[2, 3, 4])\n",
    "    union = y_pred.sum(dim=[2, 3, 4]) + y_true.sum(dim=[2, 3, 4])\n",
    "    dsc = (2.*intersection) / (union + 1e-5)\n",
    "    return torch.mean(torch.mean(dsc, dim=1))   \n",
    "\n",
    "def multi_class_dice_coefficient(label1, label2, delete_list,num_classes, include_background=True):\n",
    "    dice_coefficients = []\n",
    "\n",
    "    for class_idx in range(0 if include_background else 1, num_classes):\n",
    "        delete_flag = class_idx\n",
    "        if delete_flag in delete_list:\n",
    "            continue\n",
    "        \n",
    "        label1_binary = (label1 == class_idx).astype(int)\n",
    "        label2_binary = (label2 == class_idx).astype(int)\n",
    "        intersection = np.sum(label1_binary * label2_binary)\n",
    "        union = np.sum(label1_binary) + np.sum(label2_binary)\n",
    "\n",
    "        dice_coefficient = (2.0 * intersection) / (union + 1e-8) \n",
    "        dice_coefficients.append(dice_coefficient)\n",
    "    \n",
    "    # 过滤掉值为0的项\n",
    "    filtered_dice_coefficients = [x for x in dice_coefficients if x != 0]\n",
    "    # 计算均值\n",
    "    avg_dice = round(np.mean(filtered_dice_coefficients), 3)   \n",
    "    #avg_dice = round(np.mean(dice_coefficients), 3)           \n",
    "    return dice_coefficients,avg_dice\n",
    "# HD/HD95\n",
    "HD_metric_before = HausdorffDistanceMetric(percentile=None)\n",
    "HD_metric_after = HausdorffDistanceMetric(percentile=None)\n",
    "# Dice\n",
    "Dice_metric_before = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False,ignore_empty = True,num_classes=35)\n",
    "Dice_metric_after = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False,ignore_empty = True,num_classes=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906a4d2e-ac1a-41ea-bc08-0e7e28804273",
   "metadata": {},
   "source": [
    "# Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3494080f-20fc-419e-a44b-2a8592cb7517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test set:  39\n"
     ]
    }
   ],
   "source": [
    "#dir_save = \".\\\\experiments\\\\BCH\\\\unet_supervised\\\\\"\n",
    "#dir_save = \"./experiments/IXI/unet_supervised_lr=1e-3//\"\n",
    "dir_save = \".\\\\experiments\\\\OASIS\\\\Ablation\\\\real_image+distill\\\\\"\n",
    "batch_size = 1 \n",
    "folder_names = os.path.join(dir_save,\"test_output\")\n",
    "load_pretrained_model_weights = True\n",
    "#source_data_root = \"D:/datasets/IXI_data/Test/\" \n",
    "source_data_root = \"D:/datasets/OASIS/\" \n",
    "#source_data_root = \"D:/datasets/20230423_pairs/CT/\"\n",
    "delete_list = []#[18,19,34,35]\n",
    "test_set = Seg_OASIS_Dataset(source_data_root,is_Training=False)  # 使用你的数据根目录路径\n",
    "#test_set = Seg_CT_MRI_Dataset(source_data_root,is_Training=False) \n",
    "#test_set = Seg_IXI_Dataset(source_data_root,is_Training=False) \n",
    "# 获取数据集的长度和样本索引\n",
    "test_set_length = int(len(test_set))\n",
    "print('Length of test set: ', test_set_length)\n",
    "test_loader = DataLoader(test_set, batch_size = batch_size, shuffle = False, num_workers = 0, drop_last = False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-history",
   "metadata": {},
   "source": [
    "# Visualize registration performance of trained network\n",
    "## Load pretrained model and perform forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "swiss-nickel",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: .\\experiments\\OASIS\\Ablation\\real_image+distill\\distill_model_kpt_best_dice_55_0.8107.pth\n",
      "Dice | 0.817, std: 0.018\n",
      "Best dsc image:  ('OASIS_OAS1_0438_MR1',)\n",
      "Dice Coefficient for class 1: 0.890±0.000\n",
      "Dice Coefficient for class 2: 0.772±0.001\n",
      "Dice Coefficient for class 3: 0.914±0.001\n",
      "Dice Coefficient for class 4: 0.459±0.013\n",
      "Dice Coefficient for class 5: 0.891±0.001\n",
      "Dice Coefficient for class 6: 0.907±0.000\n",
      "Dice Coefficient for class 7: 0.929±0.000\n",
      "Dice Coefficient for class 8: 0.877±0.002\n",
      "Dice Coefficient for class 9: 0.914±0.000\n",
      "Dice Coefficient for class 10: 0.912±0.000\n",
      "Dice Coefficient for class 11: 0.851±0.003\n",
      "Dice Coefficient for class 12: 0.821±0.002\n",
      "Dice Coefficient for class 13: 0.947±0.000\n",
      "Dice Coefficient for class 14: 0.823±0.007\n",
      "Dice Coefficient for class 15: 0.847±0.000\n",
      "Dice Coefficient for class 16: 0.834±0.001\n",
      "Dice Coefficient for class 17: 0.893±0.000\n",
      "Dice Coefficient for class 18: 0.499±0.032\n",
      "Dice Coefficient for class 19: 0.567±0.005\n",
      "Dice Coefficient for class 20: 0.893±0.000\n",
      "Dice Coefficient for class 21: 0.776±0.001\n",
      "Dice Coefficient for class 22: 0.893±0.003\n",
      "Dice Coefficient for class 23: 0.553±0.014\n",
      "Dice Coefficient for class 24: 0.895±0.000\n",
      "Dice Coefficient for class 25: 0.913±0.001\n",
      "Dice Coefficient for class 26: 0.924±0.000\n",
      "Dice Coefficient for class 27: 0.858±0.005\n",
      "Dice Coefficient for class 28: 0.910±0.000\n",
      "Dice Coefficient for class 29: 0.904±0.000\n",
      "Dice Coefficient for class 30: 0.839±0.009\n",
      "Dice Coefficient for class 31: 0.857±0.001\n",
      "Dice Coefficient for class 32: 0.815±0.001\n",
      "Dice Coefficient for class 33: 0.892±0.000\n",
      "Dice Coefficient for class 34: 0.492±0.033\n",
      "Dice Coefficient for class 35: 0.573±0.006\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Test\n",
    "# ==============================================\n",
    "\n",
    "if load_pretrained_model_weights:\n",
    "    dir_load = dir_save  # folder where network weights are stored\n",
    "    # instantiate model\n",
    "    '''\n",
    "    model = myUNet(\n",
    "        in_channel=1,\n",
    "        num_class=7,\n",
    "        channel_list=(16, 32, 64, 128, 256),\n",
    "        residual=True,\n",
    "        device='cuda'\n",
    "    )\n",
    "    '''\n",
    "    model = teacher_student_model(\n",
    "    in_channel=1,\n",
    "    num_class=36,\n",
    "    channel_list=(16, 32, 64, 128, 256),\n",
    "    residual=True,\n",
    "    vae=False,\n",
    "    device='cuda'\n",
    "    )\n",
    "    \n",
    "    # load model weights\n",
    "    #filename_best_model = glob.glob(os.path.join(dir_load, \"distill_model_kpt_total_loss_best*\"))[0]\n",
    "    filename_best_model = glob.glob(os.path.join(dir_load, \"distill_model_kpt_best_dice*\"))[0]\n",
    "    #filename_best_model = glob.glob(os.path.join(dir_load, \"unet_kpt_best_dice*\"))[0]\n",
    "    model.load_state_dict(torch.load(filename_best_model))\n",
    "    print('Best model: {}'.format(filename_best_model))\n",
    "    #print(model)\n",
    "    \n",
    "model.eval()\n",
    "best_dsc = 0\n",
    "best_dsc_filename = ''\n",
    "best_dsc_pth = ''\n",
    "eval_HD = AverageMeter()\n",
    "eval_dsc = AverageMeter()\n",
    "eval_monai_dsc_def = AverageMeter()\n",
    "all_dice_coefficients = []\n",
    "all_image_avg_dice = []\n",
    "comb_all_dice_coefficients=[]\n",
    "with torch.no_grad():\n",
    "    for batch_data in test_loader:\n",
    "        # Get data\n",
    "        t0_test = time.time()\n",
    "        data = [t for t in batch_data]\n",
    "        x = data[0].cuda()\n",
    "        x_seg = data[1].cuda()\n",
    "        moving_path = data[2]\n",
    "        \n",
    "        \n",
    "        if moving_path[0]=='BCH_CT094':\n",
    "            continue\n",
    "           \n",
    "        pred_label,_ = model(x,x,is_Training=False)#重构图像就是x自己\n",
    "        teacher_features,recon,pred_label,student_features = model(x,x,is_Training=True)\n",
    "        #pred_label = model(x)\n",
    "        #print(teacher_features[0].shape)\n",
    "        pred_label = torch.argmax(pred_label, dim=1)\n",
    "        #print(\"x_seg shape: \",x_seg.shape)\n",
    "        #print(\"pred label shape: \",pred_label.squeeze().cpu().numpy().shape)\n",
    "        '''\n",
    "        # HD/HD95\n",
    "        # Transform \n",
    "        \n",
    "        transform_binary = AsDiscrete(threshold = 0.5)\n",
    "        transform_onehot = AsDiscrete(to_onehot = 2)\n",
    "\n",
    "        pred_label_binarized = transform_binary(pred_label.unsqueeze(dim=1))\n",
    "        gt_label_binarized = transform_binary(x_seg)\n",
    "        HD_metric_after(y_pred=pred_label_binarized, y=gt_label_binarized)\n",
    "        eval_HD.update(HD_metric_after.aggregate().item(), x.size(0))\n",
    "        \n",
    "        # Dice\n",
    "        dsc = utils.dice_val(pred_label.long(), x_seg.long(), 36)\n",
    "        eval_dsc.update(dsc.item(), x.size(0))\n",
    "        \n",
    "\n",
    "        print(f\"{moving_path[0]} Dice = {dsc.item()}, HD = {HD_metric_after.aggregate().item()}\")\n",
    "        \n",
    "        Dice_metric_after(y_pred=pred_label.unsqueeze(dim=1), y=x_seg)\n",
    "        eval_monai_dsc_def.update(Dice_metric_after.aggregate().item(), x.size(0))\n",
    "        print('{} Monai DSC After: {:.3f}'.format(moving_path[0],Dice_metric_after.aggregate().item()))\n",
    "                                                                     \n",
    "        Dice_metric_after.reset()\n",
    "        '''\n",
    "        \n",
    "        dice_coefficients,avg_dice = multi_class_dice_coefficient(pred_label.squeeze().cpu().numpy(), \\\n",
    "                                                                  x_seg.squeeze().cpu().numpy(),delete_list,36, include_background=False)\n",
    "        #print('{} DSC : {:.3f}'.format(moving_path[0],avg_dice))\n",
    "        # 将当前循环的 dice_coefficients 添加到列表中\n",
    "        '''\n",
    "        comb_dice_coefficients=[]\n",
    "        for i in range(1, 11):\n",
    "            j=i-1\n",
    "            comb_avg_dice = (dice_coefficients[j] + dice_coefficients[j + 19]) / 2\n",
    "            comb_dice_coefficients.append(comb_avg_dice)\n",
    "        for i in range(11,14):\n",
    "            comb_avg_dice = dice_coefficients[i-1]\n",
    "            comb_dice_coefficients.append(comb_avg_dice)\n",
    "        for i in range(14,20): \n",
    "            j=i-1\n",
    "            comb_avg_dice = (dice_coefficients[j] + dice_coefficients[j + 16]) / 2    \n",
    "            comb_dice_coefficients.append(comb_avg_dice)\n",
    "        #print(len(comb_ants_dice_coefficients))\n",
    "        comb_all_dice_coefficients.append(comb_dice_coefficients)\n",
    "        '''\n",
    "        all_dice_coefficients.append(dice_coefficients)\n",
    "        all_image_avg_dice.append(avg_dice)\n",
    "        eval_dsc.update(avg_dice)\n",
    "        \n",
    "        if avg_dice>best_dsc:\n",
    "            best_dsc_filename = moving_path\n",
    "            best_dsc_path = data[3][0]\n",
    "            best_dsc = avg_dice\n",
    "        \n",
    "        #HD_metric_after.reset()\n",
    "        '''\n",
    "        # Save Images\n",
    "        if not os.path.exists(str('./{}'.format(folder_names))):\n",
    "            os.makedirs(str('./{}'.format(folder_names)))\n",
    "        \n",
    "        fixed_image_sitk = sitk.ReadImage(\"D:/datasets/20230423_pairs/CT/BCH_CT001/brain_small_norm.nii.gz\")\n",
    "        fixed_image_sitk =  sitk.ReadImage(data[3][0])   \n",
    "        \n",
    "        fixed_image, _ = pkload(data[3][0]) \n",
    "        fixed_image = np.transpose(fixed_image, (2,1,0))\n",
    "        fixed_image_sitk = sitk.GetImageFromArray(fixed_image)\n",
    "        \n",
    "        teacher_feature_0 = sitk.GetImageFromArray(teacher_features[0].data.cpu().numpy().squeeze())\n",
    "        teacher_feature_0.SetSpacing(fixed_image_sitk.GetSpacing())\n",
    "        teacher_feature_0.SetDirection(fixed_image_sitk.GetDirection())\n",
    "        teacher_feature_0.SetOrigin(fixed_image_sitk.GetOrigin())     \n",
    "        sitk.WriteImage(teacher_feature_0,\n",
    "                        str('./{}/teacher_feature_0_{}.nii.gz'.format(\n",
    "                            folder_names, moving_path[0])))\n",
    "        \n",
    "        \n",
    "        pred_label = sitk.GetImageFromArray(pred_label.data.cpu().numpy().squeeze().astype(np.int16))\n",
    "        pred_label.SetSpacing(fixed_image_sitk.GetSpacing())\n",
    "        pred_label.SetDirection(fixed_image_sitk.GetDirection())\n",
    "        pred_label.SetOrigin(fixed_image_sitk.GetOrigin())       \n",
    "        gt_label = sitk.GetImageFromArray(x_seg.data.cpu().numpy().squeeze().astype(np.int16))\n",
    "        gt_label.SetSpacing(fixed_image_sitk.GetSpacing())\n",
    "        gt_label.SetDirection(fixed_image_sitk.GetDirection())\n",
    "        gt_label.SetOrigin(fixed_image_sitk.GetOrigin())      \n",
    "        \n",
    "        recon_img = sitk.GetImageFromArray(recon.data.cpu().numpy().squeeze())\n",
    "        recon_img.SetSpacing(fixed_image_sitk.GetSpacing())\n",
    "        recon_img.SetDirection(fixed_image_sitk.GetDirection())\n",
    "        recon_img.SetOrigin(fixed_image_sitk.GetOrigin()) \n",
    "        \n",
    "        \n",
    "        if moving_path[0]=='BCH_CT099' or moving_path[0]=='BCH_CT100':\n",
    "            sitk.WriteImage(pred_label,\n",
    "                            str('./{}/pred_label_{}.nii.gz'.format(\n",
    "                                folder_names, moving_path[0])))\n",
    "            sitk.WriteImage(gt_label,\n",
    "                            str('./{}/gt_label_{}.nii.gz'.format(\n",
    "                                folder_names, moving_path[0])))\n",
    "            #sitk.WriteImage(recon_img,str('./{}/recon_img_{}.nii.gz'.format(folder_names, moving_path[0])))\n",
    "        '''\n",
    "          \n",
    "average_dice_coefficients = np.mean(all_dice_coefficients, axis=0)\n",
    "variance_dice_coefficients = np.var(all_dice_coefficients, axis=0)        \n",
    "# metrics\n",
    "#print(f'Dice | {eval_monai_dsc_def.avg:.3f}, std: {eval_monai_dsc_def.std:.3f}')\n",
    "#print(f'HD | {eval_HD.avg:.3f}, std: {eval_HD.std:.3f}')\n",
    "print(f'Dice | {eval_dsc.avg:.3f}, std: {eval_dsc.std:.3f}')\n",
    "print('Best dsc image: ',best_dsc_filename)\n",
    "id_list = [i for i in range(1,36) if i not in []]#18, 19, 34, 35\n",
    "'''\n",
    "comb_average_dice_coefficients=[]\n",
    "comb_variance_dice_coefficients=[]\n",
    "for i in range(1, 11):\n",
    "    j=i-1\n",
    "    avg_dice = (average_dice_coefficients[j] + average_dice_coefficients[j + 19]) / 2\n",
    "    var_dice = (variance_dice_coefficients[j] + variance_dice_coefficients[j + 19]) / 2\n",
    "    comb_average_dice_coefficients.append(avg_dice)\n",
    "    comb_variance_dice_coefficients.append(var_dice)\n",
    "    print(f\"Dice Coefficient for class {id_list[j]}: {avg_dice:.3f}±{var_dice:.3f}\")\n",
    "for i in range(11,14):\n",
    "    avg_dice = average_dice_coefficients[i-1]\n",
    "    var_dice = variance_dice_coefficients[i-1] \n",
    "    comb_average_dice_coefficients.append(avg_dice)\n",
    "    comb_variance_dice_coefficients.append(var_dice)\n",
    "    print(f\"Dice Coefficient for class {id_list[i-1]}: {avg_dice:.3f}±{var_dice:.3f}\")\n",
    "for i in range(14,20): \n",
    "    j=i-1\n",
    "    avg_dice = (average_dice_coefficients[j] + average_dice_coefficients[j + 16]) / 2\n",
    "    var_dice = (variance_dice_coefficients[j] + variance_dice_coefficients[j + 16]) / 2\n",
    "    comb_average_dice_coefficients.append(avg_dice)\n",
    "    comb_variance_dice_coefficients.append(var_dice)\n",
    "    print(f\"Dice Coefficient for class {id_list[j]}: {avg_dice:.3f}±{var_dice:.3f}\")\n",
    "\n",
    "'''\n",
    "'''\n",
    "output_list = [12,23,6,5,22,1,18,4,21,8,25,16,29,9,26,7,24,3,20,13,27,10,11,14,28,2,19,15,17,30]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,30)\n",
    "    avg_dice = (average_dice_coefficients[j] + average_dice_coefficients[j + 16]) / 2\n",
    "    var_dice = (variance_dice_coefficients[j] + variance_dice_coefficients[j + 16]) / 2\n",
    "    print(f\"Dice Coefficient for class {id_list[idx-1]}: {avg_dice:.3f}±{var_dice:.3f}\")\n",
    "\n",
    "'''\n",
    "for idx, (avg_dice, var_dice) in enumerate(zip(average_dice_coefficients, variance_dice_coefficients), 1):\n",
    "    print(f\"Dice Coefficient for class {id_list[idx-1]}: {avg_dice:.3f}±{var_dice:.3f}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44cf5985-0655-46b8-97e3-0005651a7484",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\n\\n# 假设 features 是 torch.Size([1, 32, 112, 96, 80]) 的张量\\nfeatures = teacher_features[0]\\nprint(features.shape)\\n# 选择要可视化的切片索引\\nslice_index = 56  # 选择切片的索引\\n\\n# 选择在维度上的切片\\nslice_data = features[0, :,slice_index, :, :]\\n\\n# 转换为NumPy数组\\nslice_data_np = slice_data.cpu().numpy()\\n\\n# 可视化\\nplt.imshow(slice_data_np[0, :, :], cmap='viridis')  # 使用 viridis 颜色图\\nplt.title('Visualization of Feature Slice')\\nplt.colorbar()\\nplt.show()\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 假设 features 是 torch.Size([1, 32, 112, 96, 80]) 的张量\n",
    "features = teacher_features[0]\n",
    "print(features.shape)\n",
    "# 选择要可视化的切片索引\n",
    "slice_index = 56  # 选择切片的索引\n",
    "\n",
    "# 选择在维度上的切片\n",
    "slice_data = features[0, :,slice_index, :, :]\n",
    "\n",
    "# 转换为NumPy数组\n",
    "slice_data_np = slice_data.cpu().numpy()\n",
    "\n",
    "# 可视化\n",
    "plt.imshow(slice_data_np[0, :, :], cmap='viridis')  # 使用 viridis 颜色图\n",
    "plt.title('Visualization of Feature Slice')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ace86c3-7355-410d-bab0-181a9ddd0d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "print(len(all_dice_coefficients[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32235bbd-2ddf-439b-bcd6-ec6cbee3fcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_images_all_struct_dice_coefficients已保存到文件: .\\experiments\\OASIS\\Ablation\\real_image+distill\\all_images_all_struct_dice_coefficients.pkl\n",
      "all_images_dice_coefficients已保存到文件: .\\experiments\\OASIS\\Ablation\\real_image+distill\\all_images_dice_coefficients.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "#dir_save = '.\\\\experiments\\\\OASIS_IJCAI_baslines\\\\Ants-Affine\\\\'\n",
    "# 指定保存文件的路径和名称\n",
    "file_path = os.path.join(dir_save,'all_images_all_struct_dice_coefficients.pkl')\n",
    "file_path2 = os.path.join(dir_save,'all_images_dice_coefficients.pkl')\n",
    "# 使用pickle将列表保存到文件中\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(all_dice_coefficients, file)\n",
    "with open(file_path2, 'wb') as file2:\n",
    "    pickle.dump(all_image_avg_dice, file2)\n",
    "print(f'all_images_all_struct_dice_coefficients已保存到文件: {file_path}')\n",
    "print(f'all_images_dice_coefficients已保存到文件: {file_path2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3497bd3e-92e3-427e-a98f-ad71fc5157a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pickle\\n#dir_save = '.\\\\experiments\\\\ICML_baselines\\\\OASIS_ICML_baselines\\\\Ants-Affine\\\\'\\n# 指定保存文件的路径和名称\\nfile_path = os.path.join(dir_save,'comb_all_images_all_struct_dice_coefficients.pkl')\\n# 使用pickle将列表保存到文件中\\nwith open(file_path, 'wb') as file:\\n    pickle.dump(comb_all_dice_coefficients, file)\\nprint(f'all_images_all_struct_dice_coefficients已保存到文件: {file_path}')\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pickle\n",
    "#dir_save = '.\\\\experiments\\\\ICML_baselines\\\\OASIS_ICML_baselines\\\\Ants-Affine\\\\'\n",
    "# 指定保存文件的路径和名称\n",
    "file_path = os.path.join(dir_save,'comb_all_images_all_struct_dice_coefficients.pkl')\n",
    "# 使用pickle将列表保存到文件中\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(comb_all_dice_coefficients, file)\n",
    "print(f'all_images_all_struct_dice_coefficients已保存到文件: {file_path}')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
